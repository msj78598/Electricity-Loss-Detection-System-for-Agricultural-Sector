import os
import math
import pandas as pd
import requests
from pathlib import Path
from PIL import Image, ImageDraw
import torch
import joblib
from sklearn.preprocessing import StandardScaler
import streamlit as st
import urllib.parse

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ØµÙØ­Ø© Streamlit
st.set_page_config(page_title="Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙØ§Ù‚Ø¯ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ©", layout="wide")

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API Ù„Ù„Ù‚Ù…Ø± Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ
API_KEY = "AIzaSyAY7NJrBjS42s6upa9z_qgNLVXESuu366Q"
ZOOM = 15
IMG_SIZE = 640
MAP_TYPE = "satellite"

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø³Ø¨ÙŠØ© Ù„Ù„Ù…Ù„ÙØ§Øª
IMG_DIR = os.path.join(os.getcwd(), "images")
DETECTED_DIR = os.path.join(os.getcwd(), "DETECTED_FIELDS", "FIELDS", "farms")
MODEL_PATH = os.path.join(os.getcwd(), "best.pt")
ML_MODEL_PATH = os.path.join(os.getcwd(), "model", "final_model.joblib")
OUTPUT_EXCEL = os.path.join(os.getcwd(), "output", "detected_low_usage.xlsx")

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
Path(IMG_DIR).mkdir(parents=True, exist_ok=True)
Path(DETECTED_DIR).mkdir(parents=True, exist_ok=True)
Path("output").mkdir(parents=True, exist_ok=True)

# ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„Ù‚Ù…Ø± Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ
def download_image(lat, lon, meter_id):
    img_path = os.path.join(IMG_DIR, f"{meter_id}.png")
    if os.path.exists(img_path):
        return img_path
    base_url = "https://maps.googleapis.com/maps/api/staticmap"
    params = {
        "center": f"{lat},{lon}",
        "zoom": ZOOM,
        "size": f"{IMG_SIZE}x{IMG_SIZE}",
        "maptype": MAP_TYPE,
        "key": API_KEY
    }
    try:
        response = requests.get(base_url, params=params, timeout=10)
        if response.status_code == 200:
            with open(img_path, 'wb') as f:
                f.write(response.content)
            return img_path
    except Exception as e:
        print(f"Error downloading image: {e}")
        return None

# ØªØ­ÙˆÙŠÙ„ Ø¨ÙƒØ³Ù„ Ù„Ù…Ø³Ø§Ø­Ø©
def pixel_to_area(lat, box):
    scale = 156543.03392 * abs(math.cos(math.radians(lat))) / (2 ** ZOOM)
    width_m = abs(box[2] - box[0]) * scale
    height_m = abs(box[3] - box[1]) * scale
    return width_m * height_m

# ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ù€ YOLOv5
def detect_field(img_path, meter_id, info, model):
    results = model(img_path)
    df_result = results.pandas().xyxy[0]
    fields = df_result[df_result["name"] == "field"]
    if not fields.empty:
        confidence = round(fields["confidence"].max() * 100, 2)
        if confidence >= 85:
            image = Image.open(img_path).convert("RGB")
            draw = ImageDraw.Draw(image)
            largest_field = fields.iloc[0]
            box = [largest_field["xmin"], largest_field["ymin"], largest_field["xmax"], largest_field["ymax"]]
            draw.rectangle(box, outline="green", width=3)
            area = pixel_to_area(info['y'], box)
            draw.text((10, 10), f"ID: {meter_id}\nArea: {int(area)} mÂ²", fill="yellow")
            image_path = os.path.join(DETECTED_DIR, f"{meter_id}.png")
            image.save(image_path)
            return confidence, image_path, int(area)
    return None, None, None

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
def determine_priority(has_field, anomaly, consumption_check, high_priority_condition):
    if high_priority_condition:
        return "Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ù‹Ø§"
    elif has_field and anomaly == 1 and consumption_check:
        return "Ù‚ØµÙˆÙ‰"
    elif has_field and (anomaly == 1 or consumption_check):
        return "Ù…ØªÙˆØ³Ø·Ø©"
    elif has_field:
        return "Ù…Ù†Ø®ÙØ¶Ø©"
    return "Ø·Ø¨ÙŠØ¹ÙŠØ©"

# ØªØ´ØºÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ML Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø©
def predict_loss(info, model_ml):
    X = [[info["Breaker Capacity"], info["Ø§Ù„ÙƒÙ…ÙŠØ©"]]]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return model_ml.predict(X_scaled)[0]

# Ø²Ø± Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø­Ø§Ù„Ø© Ø¹Ø¨Ø± WhatsApp
def generate_whatsapp_share_link(meter_id, confidence, area, location_link, quantity, capacity, office_number, priority):
    message = f"Ø­Ø§Ù„Ø© Ø¹Ø¯Ø§Ø¯ {meter_id}:\n" \
              f"Ø±Ù‚Ù… Ø§Ù„Ù…ÙƒØªØ¨: {office_number}\n" \
              f"Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø­Ø§Ù„Ø©: {priority}\n" \
              f"Ø«Ù‚Ø©: {confidence}%\n" \
              f"Ù…Ø³Ø§Ø­Ø© ØªÙ‚Ø¯ÙŠØ±ÙŠØ©: {area} Ù…Â²\n" \
              f"ÙƒÙ…ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ: {quantity} ÙƒÙŠÙ„Ùˆ\n" \
              f"Ø³Ø¹Ø© Ø§Ù„Ù‚Ø§Ø·Ø¹: {capacity} Ø£Ù…Ø¨ÙŠØ±\n" \
              f"Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹: {location_link}"
    url = f"https://wa.me/?text={urllib.parse.quote(message)}"
    return url

# Ø¹Ø±Ø¶ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø­Ø§Ù„Ø© Ø¹Ù„Ù‰ Google Maps
def generate_google_maps_link(lat, lon):
    return f"https://www.google.com/maps?q={lat},{lon}"

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("ğŸ” Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙØ§Ù‚Ø¯ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ©")

uploaded_file = st.file_uploader("ğŸ“ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)", type=["xlsx"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    df["cont"] = df["Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ"].astype(str).str.strip()
    df["Ø§Ù„Ù…ÙƒØªØ¨"] = df["Ø§Ù„Ù…ÙƒØªØ¨"].astype(str)
    df["Ø§Ù„ÙƒÙ…ÙŠØ©"] = pd.to_numeric(df["Ø§Ù„ÙƒÙ…ÙŠØ©"], errors="coerce")

    model_yolo = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH, force_reload=True)
    model_ml = joblib.load(ML_MODEL_PATH)

    st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­")
    progress = st.progress(0)

    download_placeholder = st.empty()
    gallery_placeholder = st.empty()

    results = []
    for idx, row in df.iterrows():
        meter_id = str(row["cont"])
        lat, lon = row['y'], row['x']
        office_number = row["Ø§Ù„Ù…ÙƒØªØ¨"]
        img_path = download_image(lat, lon, meter_id)
        if img_path:
            conf, img_detected, area = detect_field(img_path, meter_id, row, model_yolo)
            if conf:
                anomaly = predict_loss(row, model_ml)
                capacity_limit = capacity_thresholds.get(row['Breaker Capacity'], 0)
                consumption_check = row['Ø§Ù„ÙƒÙ…ÙŠØ©'] < 0.5 * capacity_limit
                high_priority_condition = (conf >= 85 and row['Ø§Ù„ÙƒÙ…ÙŠØ©'] == 0) or (conf >= 85 and row['Breaker Capacity'] < 200)
                priority = determine_priority(conf >= 85, anomaly, consumption_check, high_priority_condition)

                row["Ù†Ø³Ø¨Ø©_Ø§Ù„Ø«Ù‚Ø©"] = conf
                row["Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"] = priority
                row["Ø§Ù„Ù…Ø³Ø§Ø­Ø©"] = area
                results.append(row)

                location_link = generate_google_maps_link(lat, lon)
                whatsapp_link = generate_whatsapp_share_link(meter_id, conf, area, location_link, row['Ø§Ù„ÙƒÙ…ÙŠØ©'], row['Breaker Capacity'], office_number, priority)

                df_final = pd.DataFrame(results)
                with download_placeholder:
                    with open(OUTPUT_EXCEL, "wb") as f:
                        df_final.to_excel(f, index=False)
                    with open(OUTPUT_EXCEL, "rb") as f:
                        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", data=f, file_name="detected_low_usage.xlsx", key=f"download_button_{len(results)}")

                with gallery_placeholder.container():
                    st.image(img_detected, caption=f"Ø¹Ø¯Ø§Ø¯: {meter_id}\nØ«Ù‚Ø©: {conf}%\nÙ…Ø³Ø§Ø­Ø©: {area} Ù…Â²\n{priority}\nØ§Ù„Ù…ÙƒØªØ¨: {office_number}\nØ§Ù„ÙƒÙ…ÙŠØ©: {row['Ø§Ù„ÙƒÙ…ÙŠØ©']} ÙƒÙŠÙ„Ùˆ ÙˆØ§Ø·", width=150)
                    st.markdown(f"ğŸ”— [Ù…Ø´Ø§Ø±ÙƒØ©]({whatsapp_link})")
                    st.markdown(f"ğŸ“ [Google Maps]({location_link})")

        progress.progress((idx + 1) / len(df))
